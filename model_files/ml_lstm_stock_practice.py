# -*- coding: utf-8 -*-
"""ML_LSTM_Stock_Practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmZEp0KIoIUpVSa39BTFf8u1nC-lcdJg
"""

from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load the data
appleData = pd.read_csv("AAPL.csv", parse_dates=["Date"])
appleData["Date"] = pd.to_datetime(appleData["Date"])

# Select all the relevant features
training_set = appleData[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].values

# Scale the data
sc = MinMaxScaler(feature_range=(0, 1))
training_set_scaled = sc.fit_transform(training_set)

# Define PAST_DAYS
PAST_DAYS = 100

# Create sequences
def genDataSet(trainingSet, days):
    newDataSet = []
    for i in range(days, len(trainingSet)):
        newDataSet.append(trainingSet[i - days:i])
    return np.array(newDataSet)

appleDataSet = genDataSet(training_set_scaled, PAST_DAYS)
# Convert to NumPy array

# Reshape the data
x_train, y_train = appleDataSet[:int(len(appleDataSet) * 0.7), :, :], appleDataSet[:int(len(appleDataSet) * 0.7), -1]
x_valid, y_valid = appleDataSet[int(len(appleDataSet) * 0.7):int(len(appleDataSet) * 0.9), :, :], appleDataSet[int(len(appleDataSet) * 0.7):int(len(appleDataSet) * 0.9), -1]
x_test, y_test = appleDataSet[int(len(appleDataSet) * 0.9):, :, :], appleDataSet[int(len(appleDataSet) * 0.9):, -1]


print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print("x_valid shape:", x_valid.shape)
print("y_valid shape:", y_valid.shape)
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

import matplotlib.pyplot as plt
import pandas as pd

def plot_series(series, y=None, y_pred=None, x_label="$t$", y_label="$x(t)$", legend=True):
    plt.plot(series, ".-")
    if y is not None:
        plt.plot(PAST_DAYS, y, "bo", label="Target")
    if y_pred is not None:
        plt.plot(PAST_DAYS, y_pred, "rx", markersize=10, label="Prediction")
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc="upper left")

fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(12, 4))
for col in range(2):
    plt.sca(axes[col])
    plot_series(x_valid[col, :, 0], y_valid[col, 0],
                y_label=("$x(t)$" if col==0 else None),
                legend=(col == 0))

plt.show()

# Assuming dfs["AAPL"] is your DataFrame containing stock data

# Set the specific start date
start_date = pd.to_datetime("2010-01-04")

# Filter the DataFrame to include data from the start date onwards
filtered_data = appleData[appleData["Date"] >= "2010-01-04"]

# Plot the filtered data
plt.figure(figsize=(8, 3.5))
plt.plot(filtered_data["Date"], filtered_data["Open"], marker=".", linestyle="-", color="b")
plt.grid(True)
plt.xlabel("Date")
plt.ylabel("Open")
plt.title("AAPL Open Prices")

plt.show()

import tensorflow as tf
from tensorflow import keras

np.random.seed(42)
tf.random.set_seed(42)

# Define the linear model for predicting closing price
Simple_Linear_Model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[100, 6]),  # Flatten layer to reshape the input
    keras.layers.Dense(1)  # Output layer predicting the closing price
])

# Compile the model
Simple_Linear_Model.compile(loss="mse", optimizer="adam")

# Train the model
Simple_Linear_History = Simple_Linear_Model.fit(x_train, y_train[:, 3], epochs=20,  # Predicting the last feature (closing price)
                                                validation_data=(x_valid, y_valid[:, 3]))

Simple_Linear_Model.evaluate(x_valid, y_valid[:, 3])

import matplotlib as mpl

def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, "b.-", label="Training loss")
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, "r.-", label="Validation loss")
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.legend(fontsize=14)
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.grid(True)

plot_learning_curves(Simple_Linear_History.history["loss"], Simple_Linear_History.history["val_loss"])
plt.show()

simple_linear_y_pred = Simple_Linear_Model.predict(x_valid)
plot_series(x_valid[0, :, 3], y_valid[0, 3], simple_linear_y_pred[0, 0])
plt.show()

simple_RNN_model = keras.models.Sequential([
    keras.layers.SimpleRNN(64, input_shape=[None, 6], return_sequences=True),
    keras.layers.SimpleRNN(32),
    keras.layers.Dense(1)
])

optimizer = keras.optimizers.Adam(learning_rate=0.001)
simple_RNN_model.compile(loss="mse", optimizer=optimizer, )
simple_RNN_history = simple_RNN_model.fit(x_train, y_train, epochs=50,
                    validation_data=(x_valid, y_valid))

simple_RNN_model.evaluate(x_valid, y_valid)

plot_learning_curves(simple_RNN_history.history["loss"], simple_RNN_history.history["val_loss"])
plt.show()

simple_RNN_y_pred = simple_RNN_model.predict(x_valid)
plot_series(x_valid[0, :, 3], y_valid[0, 3], simple_RNN_y_pred[0, 0])
plt.show()

np.random.seed(42)
tf.random.set_seed(42)

deep_RNN_model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 6]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.SimpleRNN(1)
])

deep_RNN_model.compile(loss="mse", optimizer="adam")
deep_RNN_history = deep_RNN_model.fit(x_train, y_train, epochs=20,
                    validation_data=(x_valid, y_valid))

deep_RNN_model.evaluate(x_valid, y_valid)

plot_learning_curves(deep_RNN_history.history["loss"], deep_RNN_history.history["val_loss"])
plt.show()

deep_RNN_y_pred = deep_RNN_model.predict(x_valid)
plot_series(x_valid[0, :, 3], y_valid[0, 3], deep_RNN_y_pred[0, 0])
plt.show()

n_steps = 50
series =  genDataSet(training_set_scaled, (n_steps + 10))

X_train = series[:int(3211*0.7), :n_steps]
X_valid = series[int(3211*0.7):int(3211*0.9), :n_steps]
X_test = series[int(3211*0.9):, :n_steps]
Y = np.empty((3211, n_steps, 6))
for step_ahead in range(1, 6):
    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]
Y_train = Y[:int(3211*0.7)]
Y_valid = Y[int(3211*0.7):int(3211*0.9)]
Y_test = Y[int(3211*0.9):]

print(X_train.shape)
print(Y_train.shape)
print(X_valid.shape)
print(Y_valid.shape)
print(X_test.shape)
print(Y_test.shape)

np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 6]),
    keras.layers.LSTM(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(6))
])

def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])

model.compile(loss="mse", optimizer="adam", metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))

np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 6]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(6))
])

def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])

model.compile(loss="mse", optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))

def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], "bo-", label="Actual")
    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], "rx-", label="Forecast", markersize=10)
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)

X = X_test

for step_ahead in range(6):
    y_pred_one = model.predict(X[:, step_ahead:])  # Remove np.newaxis here
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]
print(X_test.shape, Y_pred.shape)
plot_multiple_forecasts(X_test, Y_test, Y_pred)
plt.show()

np.random.seed(43)

X_new, Y_new = X_test[:, :50, :], Y_test[:, :, :]
Y_pred = model.predict(X_new)[..., np.newaxis]
print(Y_pred.shape)
print(Y_new.shape)
print(X_new.shape)
plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()